seed_everything: 31415

model:
  enc_desc:
    - - causal-conv3d
      - in_channels: 3
        out_channels: 128
        kernel_size: 3
    - - video-residual
      - n_rep: 4
        in_channels: 128
    - - spacetime_downsample
      - in_channels: 128
        out_channels: 128
        kernel_size: 3
        time_factor: 1
        space_factor: 2
    - - video-residual
      - in_channels: 128
        out_channels: 256
    - - video-residual
      - n_rep: 3
        in_channels: 256
    - - spacetime_downsample
      - in_channels: 256
        out_channels: 256
        kernel_size: 3
        time_factor: 2
        space_factor: 2
    - - video-residual
      - n_rep: 4
        in_channels: 256
    - - spacetime_downsample
      - in_channels: 256
        out_channels: 256
        kernel_size: 3
        time_factor: 2
        space_factor: 2
    - - video-residual
      - in_channels: 256
        out_channels: 512
    - - video-residual
      - n_rep: 7
        in_channels: 512
    - - group_norm
      - num_groups: 8
        num_channels: 512
    - - silu
      - {}
    - - causal-conv3d
      - in_channels: 512
        out_channels: 32
        kernel_size: 1
  dec_desc:
    - - causal-conv3d
      - in_channels: 32
        out_channels: 512
        kernel_size: 3
    - - video-residual
      - n_rep: 4
        in_channels: 512
    - - adaptive_group_norm
      - dim_cond: 32
        num_groups: 8
        num_channels: 512
        has_ext: True
    - - video-residual
      - n_rep: 4
        in_channels: 512
    - - depth2spacetime_upsample
      - in_channels: 512
        kernel_size: 3
        time_factor: 2
        space_factor: 2
    - - adaptive_group_norm
      - dim_cond: 32
        num_groups: 8
        num_channels: 512
        has_ext: True
    - - video-residual
      - in_channels: 512
        out_channels: 256
    - - video-residual
      - n_rep: 3
        in_channels: 256
    - - depth2spacetime_upsample
      - in_channels: 256
        kernel_size: 3
        time_factor: 2
        space_factor: 2
    - - adaptive_group_norm
      - dim_cond: 32
        num_groups: 8
        num_channels: 256
        has_ext: True
    - - video-residual
      - n_rep: 4
        in_channels: 256
    - - depth2spacetime_upsample
      - in_channels: 256
        kernel_size: 3
        time_factor: 1
        space_factor: 2
    - - adaptive_group_norm
      - dim_cond: 32
        num_groups: 8
        num_channels: 256
        has_ext: True
    - - video-residual
      - in_channels: 256
        out_channels: 128
    - - video-residual
      - n_rep: 3
        in_channels: 128
    - - group_norm
      - num_groups: 8
        num_channels: 128
    - - silu
      - {}
    - - causal-conv3d
      - in_channels: 128
        out_channels: 3
        kernel_size: 3
  disc_kwargs:
    inp_size: [64, 64] # Size of input frames
    model_dim: 128 # Dimension of the model
    num_heads: 8 # Number of (spatial) attention heads
    dim_mults: [1, 2, 4] # Channel multipliers
    down_step: [null, 2, 2] # Down-sampling steps
    inp_channels: 3
    kernel_size: 3
    num_groups: 8
    act_fn: leaky # Use LeakyReLU as activation function
    use_blur: True # Use BlurPooling for down-sampling
    use_attn: True # Discriminator can have spatial attention
  #
  d_codebook: 10
  n_codebook: 1
  #
  lfq_bias: True
  lfq_frac_sample: 1
  lfq_commit_weight: 0.25
  lfq_entropy_weight: 0.01
  lfq_diversity_weight: 1.
  #
  optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-3
      weight_decay: 0.01
  #
  perceptual_model: vgg16
  perc_feat_layers: [features.6, features.13, features.18, features.25]
  gan_discriminate: frames
  gan_frames_per_batch: 4
  gan_loss_weight: 1.
  perc_loss_weight: 1.
  quant_loss_weight: 1.

data:
  root: /home/sm/Datasets/open-genie
  env_name: Coinrun
  padding: none
  randomize: true
  transform: null
  num_frames: 16
  batch_size: 2
  output_format: c t h w
  num_workers: 16

trainer:
  max_epochs: 40
  accelerator: gpu
  devices: 1
  strategy: ddp_find_unused_parameters_false
  precision: bf16
  log_every_n_steps: 1000
  limit_val_batches: 32
  val_check_interval: 32
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        save_last: true
#  logger:
#    - class_path: lightning.pytorch.loggers.WandbLogger
#      init_args:
#        project: open-genie
#        name: genie-tokenizer
#        version: null
